{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Ch09. 단어의 표현 방법.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM4zj1bXNtyfrQvg2DqkJgL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"idEFYbZMMSVv"},"source":["* 자연어 처리에서 필수적으로 사용되는 단어의 표현 방법인 원-핫 인코딩(One-hot encoding)과 워드 임베딩(Word Embedding)에 대해서 학습\n","### 1) NLP에서의 원-핫 인코딩(One-hot encoding)"]},{"cell_type":"code","metadata":{"id":"oT6snkr4MHPu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620381419363,"user_tz":-540,"elapsed":8905,"user":{"displayName":"박재우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXI3etzUNsHKseHtKKPAfY_N2c7kAIWyXOMk2v=s64","userId":"10125744057017928750"}},"outputId":"0ecb9f40-c656-4318-d9f6-5f922134a31e"},"source":["pip install konlpy"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting konlpy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n","\u001b[K     |████████████████████████████████| 19.4MB 55.0MB/s \n","\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n","Collecting colorama\n","  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n","Collecting beautifulsoup4==4.6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n","\u001b[K     |████████████████████████████████| 92kB 7.1MB/s \n","\u001b[?25hRequirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n","Collecting JPype1>=0.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/a5/9781e2ef4ca92d09912c4794642c1653aea7607f473e156cf4d423a881a1/JPype1-1.2.1-cp37-cp37m-manylinux2010_x86_64.whl (457kB)\n","\u001b[K     |████████████████████████████████| 460kB 32.9MB/s \n","\u001b[?25hRequirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n","Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n","Installing collected packages: colorama, beautifulsoup4, JPype1, konlpy\n","  Found existing installation: beautifulsoup4 4.6.3\n","    Uninstalling beautifulsoup4-4.6.3:\n","      Successfully uninstalled beautifulsoup4-4.6.3\n","Successfully installed JPype1-1.2.1 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8aLj0MtHQfWK","executionInfo":{"status":"ok","timestamp":1620381455061,"user_tz":-540,"elapsed":9556,"user":{"displayName":"박재우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXI3etzUNsHKseHtKKPAfY_N2c7kAIWyXOMk2v=s64","userId":"10125744057017928750"}},"outputId":"dc4d5e62-8633-4908-d1f1-4969d7e9791d"},"source":["from konlpy.tag import Okt\n","okt = Okt()\n","token = okt.morphs(\"나는 자연어 처리를 배운다\")\n","print(token)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['나', '는', '자연어', '처리', '를', '배운다']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qfpVXAzmQoS7","executionInfo":{"status":"ok","timestamp":1620381676799,"user_tz":-540,"elapsed":1019,"user":{"displayName":"박재우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXI3etzUNsHKseHtKKPAfY_N2c7kAIWyXOMk2v=s64","userId":"10125744057017928750"}},"outputId":"6ab98f88-5433-4de9-998b-2bfd8097948b"},"source":["word2index = {}\n","for voca in token:\n","  if voca not in word2index.keys():\n","    word2index[voca] = len(word2index)\n","print(word2index)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'나': 0, '는': 1, '자연어': 2, '처리': 3, '를': 4, '배운다': 5}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WCLUmVsyQ7xM"},"source":["def one_hot_encoding(word, word2index):\n","  onehot_vector = [0]*(len(word2index))\n","  index = word2index[word]\n","  onehot_vector[index] = 1\n","  return onehot_vector"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lIwBAvLDRW4U","executionInfo":{"status":"ok","timestamp":1620381819738,"user_tz":-540,"elapsed":1065,"user":{"displayName":"박재우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXI3etzUNsHKseHtKKPAfY_N2c7kAIWyXOMk2v=s64","userId":"10125744057017928750"}},"outputId":"c9324bf3-4bfe-4363-cf40-39d88a1d7f99"},"source":["one_hot_encoding(\"자연어\", word2index)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0, 0, 1, 0, 0, 0]"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"-uMk7j_KSPBZ"},"source":["### 2) 워드 임베딩\n","* 원핫 인코딩은 코퍼스의 단어가 100000개라면 벡터 차원도 100000이었어야함. + 고차원 벡터이기에 메모리 낭비 + 유사도 확인 불가\n","* 그러나 밀집 벡터 이용시 벡터 차원이 조밀해짐\n","* 워드 임베딩(단어를 밀집 벡터의 형태로 표현한 방법)\n","#####  Word2Vec : CBOW vs Skip-gram\n","* CBOW : 주변단어를 갖고 중간 단어를 예측 하는 방법 \n","* Skip-gram : 중간단어를 갖고  주변단어 예측를 하는 방법 "]},{"cell_type":"code","metadata":{"id":"KC9N4PTZRXfM"},"source":["import torch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_xFUCPK6TAjL"},"source":["dog = torch.FloatTensor([1, 0, 0, 0, 0])\n","cat = torch.FloatTensor([0, 1, 0, 0, 0])\n","computer = torch.FloatTensor([0, 0, 1, 0, 0])\n","netbook = torch.FloatTensor([0, 0, 0, 1, 0])\n","book = torch.FloatTensor([0, 0, 0, 0, 1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g-5_SoAGTBgi","executionInfo":{"status":"ok","timestamp":1620382073252,"user_tz":-540,"elapsed":1114,"user":{"displayName":"박재우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXI3etzUNsHKseHtKKPAfY_N2c7kAIWyXOMk2v=s64","userId":"10125744057017928750"}},"outputId":"6d3dea85-dd37-4586-b9df-ab7212be734c"},"source":["print(torch.cosine_similarity(dog, cat, dim=0))\n","print(torch.cosine_similarity(cat, computer, dim=0))\n","print(torch.cosine_similarity(computer, netbook, dim=0))\n","print(torch.cosine_similarity(netbook, book, dim=0))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor(0.)\n","tensor(0.)\n","tensor(0.)\n","tensor(0.)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jKVNq4dob9GY"},"source":["### 4) 영어/한국어 Word2Vec 훈련시키기"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0HM1J7mwTD0T","executionInfo":{"status":"ok","timestamp":1620384756875,"user_tz":-540,"elapsed":3542,"user":{"displayName":"박재우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXI3etzUNsHKseHtKKPAfY_N2c7kAIWyXOMk2v=s64","userId":"10125744057017928750"}},"outputId":"5749ac5d-bb93-48ad-e233-39ed3c053798"},"source":["import nltk\n","nltk.download('punkt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"M3TIvzQ-dSZ6"},"source":["import urllib.request\n","import zipfile\n","from lxml import etree\n","import re\n","from nltk.tokenize import word_tokenize, sent_tokenize"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sSbRnz2ndfKq","executionInfo":{"status":"ok","timestamp":1620384826830,"user_tz":-540,"elapsed":1380,"user":{"displayName":"박재우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXI3etzUNsHKseHtKKPAfY_N2c7kAIWyXOMk2v=s64","userId":"10125744057017928750"}},"outputId":"a3bf764a-a505-4c24-8b02-8d820885c28d"},"source":["urllib.request.urlretrieve(\"https://raw.githubusercontent.com/GaoleMeng/RNN-and-FFNN-textClassification/master/ted_en-20160408.xml\", filename=\"ted_en-20160408.xml\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('ted_en-20160408.xml', <http.client.HTTPMessage at 0x7f98de581a50>)"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"om_Z0BYtdj1x"},"source":["targetXML = open('ted_en-20160408.xml', 'r', encoding='UTF8')\n","# 저자의 경우 윈도우 바탕화면에서 작업하여서 'C:\\Users\\USER\\Desktop\\ted_en-20160408.xml'이 해당 파일의 경로.  \n","target_text = etree.parse(targetXML)\n","parse_text = '\\n'.join(target_text.xpath('//content/text()'))\n","# xml 파일로부터 <content>와 </content> 사이의 내용만 가져온다.\n","\n","content_text = re.sub(r'\\([^)]*\\)', '', parse_text)\n","# 정규 표현식의 sub 모듈을 통해 content 중간에 등장하는 (Audio), (Laughter) 등의 배경음 부분을 제거.\n","# 해당 코드는 괄호로 구성된 내용을 제거.\n","\n","sent_text = sent_tokenize(content_text)\n","# 입력 코퍼스에 대해서 NLTK를 이용하여 문장 토큰화를 수행.\n","\n","normalized_text = []\n","for string in sent_text:\n","     tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n","     normalized_text.append(tokens)\n","# 각 문장에 대해서 구두점을 제거하고, 대문자를 소문자로 변환.\n","\n","result = []\n","result = [word_tokenize(sentence) for sentence in normalized_text]\n","# 각 문장에 대해서 NLTK를 이용하여 단어 토큰화를 수행."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yb-mXajzdynd","executionInfo":{"status":"ok","timestamp":1620384937375,"user_tz":-540,"elapsed":1480,"user":{"displayName":"박재우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXI3etzUNsHKseHtKKPAfY_N2c7kAIWyXOMk2v=s64","userId":"10125744057017928750"}},"outputId":"9d4d5d5d-04b3-47b2-a5b0-705e3c97d7ce"},"source":["print('총 샘플의 개수 : {}'.format(len(result)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["총 샘플의 개수 : 273424\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nVWasw6td--V","executionInfo":{"status":"ok","timestamp":1620384979563,"user_tz":-540,"elapsed":812,"user":{"displayName":"박재우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXI3etzUNsHKseHtKKPAfY_N2c7kAIWyXOMk2v=s64","userId":"10125744057017928750"}},"outputId":"5a5551ae-f02c-4df0-8f27-df601d8e084a"},"source":["for line in result[:3]: # 샘플 3개만 출력\n","    print(line)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['here', 'are', 'two', 'reasons', 'companies', 'fail', 'they', 'only', 'do', 'more', 'of', 'the', 'same', 'or', 'they', 'only', 'do', 'what', 's', 'new']\n","['to', 'me', 'the', 'real', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', 'exploration', 'and', 'exploitation']\n","['both', 'are', 'necessary', 'but', 'it', 'can', 'be', 'too', 'much', 'of', 'a', 'good', 'thing']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":71},"id":"Pe_yNDz4eCgi","executionInfo":{"status":"ok","timestamp":1620385134250,"user_tz":-540,"elapsed":36830,"user":{"displayName":"박재우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXI3etzUNsHKseHtKKPAfY_N2c7kAIWyXOMk2v=s64","userId":"10125744057017928750"}},"outputId":"e5495b9f-2406-4612-be4e-5bdadc70141d"},"source":["from gensim.models import Word2Vec, KeyedVectors\n","model = Word2Vec(sentences=result, size=100, window=5, min_count=5, workers=4, sg=0)\n","'''\n","size = 워드 벡터의 특징 값. 즉, 임베딩 된 벡터의 차원.\n","window = 컨텍스트 윈도우 크기\n","min_count = 단어 최소 빈도 수 제한 (빈도가 적은 단어들은 학습하지 않는다.)\n","workers = 학습을 위한 프로세스 수\n","sg = 0은 CBOW, 1은 Skip-gram.\n","'''"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nsize = 워드 벡터의 특징 값. 즉, 임베딩 된 벡터의 차원.\\nwindow = 컨텍스트 윈도우 크기\\nmin_count = 단어 최소 빈도 수 제한 (빈도가 적은 단어들은 학습하지 않는다.)\\nworkers = 학습을 위한 프로세스 수\\nsg = 0은 CBOW, 1은 Skip-gram.\\n'"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y_JJGwMuemZf","executionInfo":{"status":"ok","timestamp":1620385165855,"user_tz":-540,"elapsed":790,"user":{"displayName":"박재우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXI3etzUNsHKseHtKKPAfY_N2c7kAIWyXOMk2v=s64","userId":"10125744057017928750"}},"outputId":"640d82d3-c403-46a2-d633-91bb25ea0a50"},"source":["model_result = model.wv.most_similar(\"boy\")\n","print(model_result)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[('girl', 0.923625111579895), ('kid', 0.8343952894210815), ('lady', 0.8081405758857727), ('woman', 0.7867289185523987), ('man', 0.7692819833755493), ('mary', 0.759153425693512), ('sister', 0.7238417863845825), ('brother', 0.7158746719360352), ('baby', 0.7107657194137573), ('guy', 0.702812135219574)]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yipuICSPey2t"},"source":["model.wv.save_word2vec_format('./eng_w2v')\n","load_model = KeyedVectors.load_word2vec_format('eng_w2v')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3XIr2GFvfIlQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620385251920,"user_tz":-540,"elapsed":827,"user":{"displayName":"박재우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXI3etzUNsHKseHtKKPAfY_N2c7kAIWyXOMk2v=s64","userId":"10125744057017928750"}},"outputId":"3313421d-833a-4050-9b17-1151ca73ff34"},"source":["model_result = load_model.most_similar(\"boy\")\n","print(model_result)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[('girl', 0.923625111579895), ('kid', 0.8343952894210815), ('lady', 0.8081405758857727), ('woman', 0.7867289185523987), ('man', 0.7692819833755493), ('mary', 0.759153425693512), ('sister', 0.7238417863845825), ('brother', 0.7158746719360352), ('baby', 0.7107657194137573), ('guy', 0.702812135219574)]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ul4OZypLc2gA"},"source":["import gensim\n","\n","model = gensim.models.KeyedVectors.load_word2vec_format('파일 경로', binary=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QYzua5iAdpuU"},"source":["print(model.vectors.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H5puxvKzdqNP"},"source":["print (model.similarity('this', 'is')) # 두 단어의 유사도 계산하기\n","print (model.similarity('post', 'book'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4uAl3-1gdzb0"},"source":["### 6). 글로브(GloVe)\n","* 카운트 기반과 예측 기반을 모두 사용하는 방법론\n","* 예측기반의 Word2Vec의 단점을 보안한다는 목적을 가짐\n","* LSA(카운트/ 통계 기반) : 통계적 정보를 고려하지만 단어 의미와 유추작업에는 부족함\n","* Word2Vec(예측 기반) : 유추작업에는 뛰어나지만, 윈도우 크기 내에서만 주변 단어를 고려하기에 코퍼스 전체적인 통계 정보를 반영하지 못함\n","* => '임베딩 된 중심 단어와 주변 단어 벡터의 내적이 전체 코퍼스에서의 동시 등장 확률이 되도록 만드는 것'"]},{"cell_type":"markdown","metadata":{"id":"NIC4rBz7h5NS"},"source":["### 7) 파이토치(PyTorch)의 nn.Embedding()"]},{"cell_type":"code","metadata":{"id":"rvioUTH0jIlE"},"source":["import torch\n","import torch.nn as nn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4M5UzLtFh40e"},"source":["train_data = \"you need to know how to code\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gKz4d5qudqWK","executionInfo":{"status":"ok","timestamp":1620470085736,"user_tz":-540,"elapsed":827,"user":{"displayName":"박재우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXI3etzUNsHKseHtKKPAfY_N2c7kAIWyXOMk2v=s64","userId":"10125744057017928750"}},"outputId":"8d702a0a-c6d2-4faa-db93-5a95335cd60c"},"source":["word_set = set(train_data.split()) # set : 중복된 단어를 제거하여 집합 생성\n","word_set"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'code', 'how', 'know', 'need', 'to', 'you'}"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7FzxTXzhiZl8","executionInfo":{"status":"ok","timestamp":1620470142953,"user_tz":-540,"elapsed":810,"user":{"displayName":"박재우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXI3etzUNsHKseHtKKPAfY_N2c7kAIWyXOMk2v=s64","userId":"10125744057017928750"}},"outputId":"352dbc05-bab4-4e18-c390-9da85a62034f"},"source":["vocab = {word: i+2 for i, word in enumerate(word_set)}\n","vocab['<unk>'] = 0\n","vocab['<pad>'] = 1\n","print(vocab)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'need': 2, 'know': 3, 'to': 4, 'code': 5, 'how': 6, 'you': 7, '<unk>': 0, '<pad>': 1}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oeWTsxqpisjR"},"source":["embedding_table = torch.FloatTensor([\n","                               [ 0.0,  0.0,  0.0],\n","                               [ 0.0,  0.0,  0.0],\n","                               [ 0.2,  0.9,  0.3],\n","                               [ 0.1,  0.5,  0.7],\n","                               [ 0.2,  0.1,  0.8],\n","                               [ 0.4,  0.1,  0.1],\n","                               [ 0.1,  0.8,  0.9],\n","                               [ 0.6,  0.1,  0.1]])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Ohy4hpwjHPn","executionInfo":{"status":"ok","timestamp":1620470357642,"user_tz":-540,"elapsed":1153,"user":{"displayName":"박재우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXI3etzUNsHKseHtKKPAfY_N2c7kAIWyXOMk2v=s64","userId":"10125744057017928750"}},"outputId":"96c34030-0731-46d8-a1f6-149728849303"},"source":["sample = \"you need to run\".split()\n","index = []\n","\n","for word in sample:\n","  try:\n","    index.append(vocab[word])\n","  except KeyError:\n","    index.append(vocab['<unk>'])\n","\n","index = torch.LongTensor(index)\n","\n","lookup_result = embedding_table[index, :]\n","print(index)\n","print(lookup_result)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([7, 2, 4, 0])\n","tensor([[0.6000, 0.1000, 0.1000],\n","        [0.2000, 0.9000, 0.3000],\n","        [0.2000, 0.1000, 0.8000],\n","        [0.0000, 0.0000, 0.0000]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"frgr65aRjzeQ","executionInfo":{"status":"ok","timestamp":1620470462837,"user_tz":-540,"elapsed":539,"user":{"displayName":"박재우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXI3etzUNsHKseHtKKPAfY_N2c7kAIWyXOMk2v=s64","userId":"10125744057017928750"}},"outputId":"da64859d-f704-448b-c7cc-7dbc721f4bcf"},"source":["train_data = \"you need to know how to code\"\n","word_set = set(train_data.split())\n","\n","vocab = {word: i+2 for i, word in enumerate(word_set)}\n","vocab['<unk>'] = 0\n","vocab['<pad>'] = 1\n","\n","print(vocab)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'need': 2, 'know': 3, 'to': 4, 'code': 5, 'how': 6, 'you': 7, '<unk>': 0, '<pad>': 1}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":71},"id":"g1si4H7JkNp2","executionInfo":{"status":"ok","timestamp":1620470534647,"user_tz":-540,"elapsed":748,"user":{"displayName":"박재우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXI3etzUNsHKseHtKKPAfY_N2c7kAIWyXOMk2v=s64","userId":"10125744057017928750"}},"outputId":"c4055309-ee61-438e-d369-6fa4bbc50c9f"},"source":["embedding_layer = nn.Embedding(num_embeddings=len(vocab),\n","                               embedding_dim=3,\n","                               padding_idx=1)\n","'''\n","num_embeddings : 임베딩을 할 단어들의 개수. 다시 말해 단어 집합의 크기입니다.\n","embedding_dim : 임베딩 할 벡터의 차원입니다. 사용자가 정해주는 하이퍼파라미터입니다.\n","padding_idx : 선택적으로 사용하는 인자입니다. 패딩을 위한 토큰의 인덱스를 알려줍니다.\n","'''"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nnum_embeddings : 임베딩을 할 단어들의 개수. 다시 말해 단어 집합의 크기입니다.\\nembedding_dim : 임베딩 할 벡터의 차원입니다. 사용자가 정해주는 하이퍼파라미터입니다.\\npadding_idx : 선택적으로 사용하는 인자입니다. 패딩을 위한 토큰의 인덱스를 알려줍니다.\\n'"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YZikQMM1kg7F","executionInfo":{"status":"ok","timestamp":1620470542527,"user_tz":-540,"elapsed":820,"user":{"displayName":"박재우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXI3etzUNsHKseHtKKPAfY_N2c7kAIWyXOMk2v=s64","userId":"10125744057017928750"}},"outputId":"1201963a-a288-4f85-c57c-ba51ec7230ac"},"source":["print(embedding_layer.weight)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Parameter containing:\n","tensor([[ 0.4610, -0.3534, -0.3346],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [-0.3596, -1.6494,  0.6563],\n","        [ 0.3017, -1.2605,  0.2688],\n","        [ 1.1220, -0.2450, -0.7597],\n","        [ 0.3690,  0.5782, -1.2220],\n","        [ 0.2117,  0.0300,  2.8962],\n","        [-0.4455,  1.2290, -0.3402]], requires_grad=True)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xnYPO1ALkleH"},"source":["### 8) 사전 훈련된 워드 임베딩(Pretrained Word Embedding)"]},{"cell_type":"code","metadata":{"id":"ehkrk93Fkiq4","executionInfo":{"status":"ok","timestamp":1620480027412,"user_tz":-540,"elapsed":707,"user":{"displayName":"박재우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXI3etzUNsHKseHtKKPAfY_N2c7kAIWyXOMk2v=s64","userId":"10125744057017928750"}}},"source":["import torch\n","import torch.nn as nn\n","\n","from torchtext.legacy import data, datasets"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"68EOr29PIKPW","executionInfo":{"status":"ok","timestamp":1620481466554,"user_tz":-540,"elapsed":644,"user":{"displayName":"박재우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXI3etzUNsHKseHtKKPAfY_N2c7kAIWyXOMk2v=s64","userId":"10125744057017928750"}}},"source":["# 두개의 Field 객체 정의\n","TEXT = data.Field(sequential=True, batch_first=True, lower=True)\n","LABEL = data.Field(sequential=False, batch_first=True)"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"TFzBLTtIIXnG"},"source":["train_set, test_set = datasets.IMDB.splits(TEXT, LABEL)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H_eAS1OcJGf8","executionInfo":{"status":"ok","timestamp":1620481321657,"user_tz":-540,"elapsed":668,"user":{"displayName":"박재우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXI3etzUNsHKseHtKKPAfY_N2c7kAIWyXOMk2v=s64","userId":"10125744057017928750"}},"outputId":"9eeccd7c-c1c7-4c3a-de61-d0de09a4361c"},"source":["print('훈련 데이터의 크기 : {}' .format(len(train_set)))"],"execution_count":28,"outputs":[{"output_type":"stream","text":["훈련 데이터의 크기 : 25000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZFGpOGlJKod1","executionInfo":{"status":"ok","timestamp":1620480539930,"user_tz":-540,"elapsed":686,"user":{"displayName":"박재우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXI3etzUNsHKseHtKKPAfY_N2c7kAIWyXOMk2v=s64","userId":"10125744057017928750"}},"outputId":"bf8b0a83-2a23-4ce7-f296-a62c88980946"},"source":["print('테스트 데이터의 크기 : {}' .format(len(test_set)))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["테스트 데이터의 크기 : 25000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5N6duXzVKroe","executionInfo":{"status":"ok","timestamp":1620480562976,"user_tz":-540,"elapsed":795,"user":{"displayName":"박재우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXI3etzUNsHKseHtKKPAfY_N2c7kAIWyXOMk2v=s64","userId":"10125744057017928750"}},"outputId":"a2fefdeb-4ae7-4662-cc1c-e8565e69129c"},"source":["print(vars(train_set[0]))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["{'text': ['i', 'have', 'seen', 'the', 'trailer', 'for', 'this', 'movie', 'several', 'times', 'over,', 'and', 'i', 'have', 'to', 'say', 'that', 'ned', 'kelly', 'looks', 'like', 'it', 'is', 'going', 'to', 'be', 'a', 'wonderful', 'film.', 'when', 'i', 'saw', 'the', 'trailer', 'for', 'the', 'first', 'time,', 'i', 'could', 'not', 'take', 'my', 'eyes', 'away', 'from', 'it', '(it', 'got', 'my', 'attention', 'for', 'sure).', 'heath', 'ledger', 'sticks', 'to', 'what', 'he', 'knows', 'and', 'what', 'works', 'for', 'him,', 'period', 'pieces.', 'not', 'to', 'mention', 'orlando', 'bloom', ',who', 'is', 'seen', 'for', 'a', 'split', 'second', 'looks', 'fantastic.', 'i', 'think', 'that', 'this', 'movie', 'will', 'be', 'a', 'hit,', 'and', 'will', 'be', 'seen', 'over', 'and', 'over', 'again', 'my', 'many', 'people.'], 'label': 'pos'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sPTS71V9KxGj","executionInfo":{"status":"ok","timestamp":1620480597486,"user_tz":-540,"elapsed":759,"user":{"displayName":"박재우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXI3etzUNsHKseHtKKPAfY_N2c7kAIWyXOMk2v=s64","userId":"10125744057017928750"}}},"source":["#Field 객체의 build_vocab을 통해 사전 훈련된 워드 임베딩을 사용할 수 있음"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"DCjmlyA9K4KZ","executionInfo":{"status":"ok","timestamp":1620480660784,"user_tz":-540,"elapsed":699,"user":{"displayName":"박재우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXI3etzUNsHKseHtKKPAfY_N2c7kAIWyXOMk2v=s64","userId":"10125744057017928750"}}},"source":["from gensim.models import KeyedVectors"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"TyFvQU6NLJIx"},"source":["word2vec_model = KeyedVectors.load_word2vec_format('eng_w2v')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5CVL0woXLOVU"},"source":["print(word2vec_model['this']) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"744xlYQBLZeR","executionInfo":{"status":"ok","timestamp":1620480830617,"user_tz":-540,"elapsed":787,"user":{"displayName":"박재우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXI3etzUNsHKseHtKKPAfY_N2c7kAIWyXOMk2v=s64","userId":"10125744057017928750"}}},"source":["from torchtext.vocab import GloVe"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"3-eK0xUSLZu6","executionInfo":{"status":"ok","timestamp":1620481455839,"user_tz":-540,"elapsed":1414,"user":{"displayName":"박재우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXI3etzUNsHKseHtKKPAfY_N2c7kAIWyXOMk2v=s64","userId":"10125744057017928750"}}},"source":["TEXT.build_vocab(train_set, vectors=GloVe(name='6B', dim=300), max_size=10000, min_freq=10)\n","LABEL.build_vocab(train_set)"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xr6qmuCELZ2e","executionInfo":{"status":"ok","timestamp":1620481260808,"user_tz":-540,"elapsed":769,"user":{"displayName":"박재우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXI3etzUNsHKseHtKKPAfY_N2c7kAIWyXOMk2v=s64","userId":"10125744057017928750"}},"outputId":"37b242ba-1910-444b-85ee-64c0a34191c9"},"source":["print(TEXT.vocab.stoi)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x7f9a34848a10>>, {'<unk>': 0, '<pad>': 1})\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WUeiyCO2LZ5g","executionInfo":{"status":"ok","timestamp":1620481460827,"user_tz":-540,"elapsed":688,"user":{"displayName":"박재우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXI3etzUNsHKseHtKKPAfY_N2c7kAIWyXOMk2v=s64","userId":"10125744057017928750"}},"outputId":"9a4e2b93-d9eb-4413-eb85-f170860f0f69"},"source":["print('임베딩 벡터의 개수와 차원 : {} '.format(TEXT.vocab.vectors.shape))"],"execution_count":33,"outputs":[{"output_type":"stream","text":["임베딩 벡터의 개수와 차원 : torch.Size([2, 300]) \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U_wERaBHLZ8x","executionInfo":{"status":"ok","timestamp":1620481260809,"user_tz":-540,"elapsed":759,"user":{"displayName":"박재우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXI3etzUNsHKseHtKKPAfY_N2c7kAIWyXOMk2v=s64","userId":"10125744057017928750"}},"outputId":"a97d4de0-f3ab-4b62-ae78-52a5ceda7dc0"},"source":["print(TEXT.vocab.vectors[0])"],"execution_count":25,"outputs":[{"output_type":"stream","text":["tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WEIIBBH2NO4J","executionInfo":{"status":"ok","timestamp":1620481260809,"user_tz":-540,"elapsed":757,"user":{"displayName":"박재우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXI3etzUNsHKseHtKKPAfY_N2c7kAIWyXOMk2v=s64","userId":"10125744057017928750"}},"outputId":"5a875555-7f24-475f-d5b5-9a681751eaf4"},"source":["print(TEXT.vocab.vectors[1]) "],"execution_count":26,"outputs":[{"output_type":"stream","text":["tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V-8RutznNPYc","executionInfo":{"status":"ok","timestamp":1620481260810,"user_tz":-540,"elapsed":756,"user":{"displayName":"박재우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXI3etzUNsHKseHtKKPAfY_N2c7kAIWyXOMk2v=s64","userId":"10125744057017928750"}}},"source":["embedding_layer = nn.Embedding.from_pretrained(TEXT.vocab.vectors, freeze=False)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"O8HVyaD-NSMg"},"source":[""],"execution_count":null,"outputs":[]}]}