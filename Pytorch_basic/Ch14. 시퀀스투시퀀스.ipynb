{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Ch14. 시퀀스투시퀀스.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMKK5dNkuRbt7FXIIo2Dn/8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"MRjiWWF2GfPi"},"source":["### 1) 시퀀스투시퀀스(Sequence-to-Sequence, seq2seq)"]},{"cell_type":"markdown","metadata":{"id":"eoh7Skgq_E2Z"},"source":["#### 01. 모델의 개요(Overview)\n","* 입력시퀀스로부터 다른 도메인의 시퀀스를 출력하는 다양한 분야에서 사용되는 모델 (인코더 -> 디코더)\n","* 입코더는 입력 문장의 모든 단어들을 순차적을 입력받은 뒤에 마지막에 모든 정보를 압축해서 하나의 벡터로 만듦 (이를 컨텍스트 벡터라고함)\n","* 컨텍스트 벡터로 압축된 정보는 인코더에서 디코더로 전송됨. 디코더는 컨텍스트 벡터를 받아서 번역된 단어를 한개씩 순차적으로 출력함\n","\n","\n","#### 02. seq2seq의 동작 과정\n","* 인코더 RNN 셀의 마지막 시점의 은닉 상태를 디코더 RNN의 첫번쨰 셀로 넘겨주는데 이를 컨텍스트 벡터라고 함\n","\n","###### --- 02-1. 테스트 단계\n","* 디코더는 초기입력의 문장에서 <sos>를 입력받으면 다음에 등장할 확률이 높은 단어를 예측함\n","* 그 이후 예측한 단어를 다음 시점의 RNN셀의 입력으로 넣는 행위를 반복\n","* 이 행위는 문장의 끝을 의미하는 <eos>가 다음단어로 예측될때까지 반복\n","\n","###### --- 02-2. 훈련 단계와 교사 강요\n","* 훈련과정에서 디코더에게 인코더가 보낸 컨텍스트 벡터 <sos> je suis étudiant를 입력 받았을 때, je suis étudiant <eos>가 나와야 된다고 정답을 알려주면서 훈련합니다. => 교사 강요\n","* 반면 테스트 과정에서 디코더는 오직 컨텍스트 벡터와 <go>만을 입력으로 받은 후에 다음에 올 단어를 예측하고, 그 단어를 다음 시점의 RNN 셀의 입력으로 넣는 행위를 반복\n","\n","###### --- 02-5. 디코더\n","* 디코더의 첫번째 RNN 셀은 이 첫번째 은닉 상태의 값과, 현재 t에서의 입력값인 <sos>로부터, 다음에 등장할 단어를 예측함. 그리고 이 예측된 단어는 다음 시점인 t+1 RNN에서의 입력값이 되고, 이 t+1에서의 RNN 또한 이 입력값과 t에서의 은닉 상태로부터 t+1에서의 출력 벡터. 즉, 또 다시 다음에 등장할 단어를 예측\n","* seq2seq 모델은 선택될 수 있는 모든 단어들로부터 하나의 단어를 골라서 예측해야 하기에 소프트맥스 함수를 사용"]},{"cell_type":"code","metadata":{"id":"ng5hOtKPGiaj"},"source":[""],"execution_count":null,"outputs":[]}]}